{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import Discriminator, Generator,intialize_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DETERMINES WHETHER TO USE GPU (CUDA) OR CPU FOR COMPUTATIONS\n",
    "# ADVANTAGES: AUTOMATICALLY USES GPU IF AVAILABLE FOR FASTER PROCESSING\n",
    "\n",
    "LEARNING_RATE = 2e-4\n",
    "# SETS THE LEARNING RATE FOR THE OPTIMIZER\n",
    "# ADVANTAGES: SMALL LEARNING RATE HELPS IN STABLE TRAINING OF GANs\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# NUMBER OF IMAGES PROCESSED IN EACH TRAINING ITERATION\n",
    "# ADVANTAGES: LARGER BATCH SIZE CAN LEAD TO MORE STABLE GRADIENTS\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "# DEFINES THE DIMENSIONS OF THE IMAGES (64x64 PIXELS)\n",
    "# ADVANTAGES: STANDARD SIZE FOR DCGAN, BALANCES DETAIL AND COMPUTATION\n",
    "\n",
    "CHANNELS_IMG = 1\n",
    "# NUMBER OF COLOR CHANNELS (1 FOR GRAYSCALE, 3 FOR RGB)\n",
    "# ADVANTAGES: ALLOWS FLEXIBILITY IN INPUT IMAGE TYPE\n",
    "\n",
    "Z_DIM = 100\n",
    "# DIMENSION OF THE LATENT SPACE VECTOR\n",
    "# ADVANTAGES: PROVIDES ENOUGH VARIABILITY FOR GENERATOR INPUT\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "# NUMBER OF TIMES TO ITERATE THROUGH THE ENTIRE DATASET\n",
    "# ADVANTAGES: ALLOWS FOR MULTIPLE PASSES OVER DATA FOR BETTER LEARNING\n",
    "\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "# STARTING NUMBER OF FEATURES FOR DISCRIMINATOR AND GENERATOR\n",
    "# ADVANTAGES: ALLOWS FOR EASY SCALING OF NETWORK COMPLEXITY\n",
    "\n",
    "NOISE_DIM = 100\n",
    "# DIMENSION OF NOISE VECTOR (SAME AS Z_DIM)\n",
    "# ADVANTAGES: CONSISTENCY IN GENERATOR INPUT\n",
    "\n",
    "# TRANSFORMS\n",
    "from torchvision import transforms\n",
    "# IMPORT THE TRANSFORMS MODULE FROM TORCHVISION\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# COMPOSE COMBINES MULTIPLE TRANSFORMS INTO A SINGLE TRANSFORM\n",
    "# ADVANTAGES: ALLOWS FOR EASY APPLICATION OF MULTIPLE PREPROCESSING STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(image_dim),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "\n",
    "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms, download=False)\n",
    "\n",
    "# CREATE DATA LOADER\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# INITIALIZE GENERATOR AND DISCRIMINATOR\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "intialize_weights(gen)\n",
    "intialize_weights(disc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP OPTIMIZERS\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# DEFINE LOSS FUNCTION\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# SETUP TENSORBOARD\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 0/469                   Loss D: 0.6961, loss G: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "# SET GENERATOR AND DISCRIMINATOR TO TRAINING MODE\n",
    "# ENABLES GRADIENT COMPUTATION AND BATCH NORMALIZATION UPDATES\n",
    "# CRUCIAL FOR PROPER TRAINING OF NEURAL NETWORKS\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        # ITERATE THROUGH EPOCHS AND BATCHES\n",
    "        # MOVE REAL IMAGES TO DEVICE (GPU/CPU)\n",
    "        # GENERATE RANDOM NOISE AND CREATE FAKE IMAGES\n",
    "        # ENSURES EFFICIENT PROCESSING AND CONSISTENT TRAINING ACROSS DEVICES\n",
    "\n",
    "        # TRAIN DISCRIMINATOR\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake.detach()).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # COMPUTE DISCRIMINATOR LOSS FOR REAL AND FAKE IMAGES\n",
    "        # USE BINARY CROSS-ENTROPY LOSS\n",
    "        # DETACH FAKE IMAGES TO PREVENT GENERATOR UPDATES\n",
    "        # AVERAGE REAL AND FAKE LOSSES\n",
    "        # PERFORM BACKPROPAGATION AND OPTIMIZATION\n",
    "        # IMPROVES DISCRIMINATOR'S ABILITY TO DISTINGUISH REAL FROM FAKE\n",
    "\n",
    "        # TRAIN GENERATOR\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # COMPUTE GENERATOR LOSS\n",
    "        # USE BINARY CROSS-ENTROPY LOSS\n",
    "        # PERFORM BACKPROPAGATION AND OPTIMIZATION\n",
    "        # IMPROVES GENERATOR'S ABILITY TO PRODUCE REALISTIC IMAGES\n",
    "\n",
    "        # PRINT LOSSES AND VISUALIZE PROGRESS\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "            step += 1\n",
    "\n",
    "        # PERIODICALLY PRINT TRAINING PROGRESS\n",
    "        # GENERATE FAKE IMAGES FROM FIXED NOISE FOR CONSISTENCY\n",
    "        # CREATE IMAGE GRIDS FOR REAL AND FAKE IMAGES\n",
    "        # LOG IMAGES TO TENSORBOARD FOR VISUALIZATION\n",
    "        # HELPS MONITOR TRAINING PROGRESS AND QUALITY OF GENERATED IMAGES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
