{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                     # - IMPORT PYTORCH LIBRARY\n",
    "import torch.nn as nn                            # - IMPORT NEURAL NETWORK MODULE\n",
    "import torch.optim as optim                      # - IMPORT OPTIMIZATION ALGORITHMS\n",
    "import torchvision                               # - IMPORT COMPUTER VISION LIBRARY\n",
    "import torchvision.datasets as datasets          # - IMPORT DATASET UTILITIES\n",
    "from torch.utils.data import DataLoader          # - IMPORT DATA LOADING TOOL\n",
    "import torchvision.transforms as transforms      # - IMPORT DATA TRANSFORMATION TOOLS\n",
    "from torch.utils.tensorboard import SummaryWriter # - IMPORT VISUALIZATION TOOL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim,128),      # - INPUT LAYER: TRANSFORMS IMAGE TO HIDDEN LAYER\n",
    "            nn.LeakyReLU(0.1),           # - ACTIVATION: ALLOWS SMALL NEGATIVE VALUES\n",
    "            nn.Linear(128,1),            # - OUTPUT LAYER: PRODUCES SINGLE SCORE\n",
    "            nn.Sigmoid(),                # - ACTIVATION: SQUASHES OUTPUT TO 0-1 RANGE\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)    # - FORWARD PASS: PROCESSES INPUT THROUGH NETWORK\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),       # - INPUT LAYER: TRANSFORMS NOISE TO HIDDEN LAYER\n",
    "            nn.LeakyReLU(0.1),           # - ACTIVATION: ALLOWS SMALL NEGATIVE VALUES\n",
    "            nn.Linear(256, img_dim),     # - OUTPUT LAYER: PRODUCES FAKE IMAGE\n",
    "            nn.Tanh(),                   # - ACTIVATION: SQUASHES OUTPUT TO -1 TO 1 RANGE\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)     # - FORWARD PASS: GENERATES FAKE IMAGE FROM INPUT NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:15<00:00, 636368.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 63882.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:09<00:00, 181550.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1400156.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# HYPER PARAMETERS\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # - SET DEVICE TO GPU IF AVAILABLE\n",
    "lr = 3e-4                                               # - LEARNING RATE FOR OPTIMIZATION\n",
    "z_dim = 64                                              # - DIMENSION OF NOISE INPUT\n",
    "image_dim = 28 * 28 * 1                                 # - FLATTENED MNIST IMAGE DIMENSION\n",
    "batch_size = 32                                         # - NUMBER OF SAMPLES PER BATCH\n",
    "num_epochs = 50                                         # - NUMBER OF TRAINING ITERATIONS\n",
    "\n",
    "disc = Discriminator(image_dim).to(device)              # - CREATE AND MOVE DISCRIMINATOR TO DEVICE\n",
    "gen = Generator(z_dim, image_dim).to(device)            # - CREATE AND MOVE GENERATOR TO DEVICE\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device) # - CREATE FIXED NOISE FOR VISUALIZATION\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))] # - PREPROCESS IMAGES\n",
    ")\n",
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True) # - LOAD MNIST DATASET\n",
    "loader = DataLoader(dataset,batch_size=batch_size, shuffle=True) # - CREATE DATA LOADER\n",
    "\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)         # - OPTIMIZER FOR DISCRIMINATOR\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)           # - OPTIMIZER FOR GENERATOR\n",
    "criterion = nn.BCELoss()                                # - BINARY CROSS ENTROPY LOSS FUNCTION\n",
    "\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")     # - TENSORBOARD WRITER FOR FAKE IMAGES\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")     # - TENSORBOARD WRITER FOR REAL IMAGES\n",
    "steps = 0                                               # - COUNTER FOR TRAINING STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Loss D: 0.6733, Loss G: 0.7109\n",
      "Epoch [1/50] Loss D: 0.2048, Loss G: 1.9953\n",
      "Epoch [2/50] Loss D: 0.1054, Loss G: 2.9619\n",
      "Epoch [3/50] Loss D: 0.0380, Loss G: 3.7025\n",
      "Epoch [4/50] Loss D: 0.1167, Loss G: 4.6240\n",
      "Epoch [5/50] Loss D: 0.0120, Loss G: 4.7344\n",
      "Epoch [6/50] Loss D: 0.0121, Loss G: 5.0336\n",
      "Epoch [7/50] Loss D: 0.0411, Loss G: 4.7770\n",
      "Epoch [8/50] Loss D: 0.0186, Loss G: 5.4537\n",
      "Epoch [9/50] Loss D: 0.1231, Loss G: 4.1787\n",
      "Epoch [10/50] Loss D: 0.0102, Loss G: 6.5711\n",
      "Epoch [11/50] Loss D: 0.0070, Loss G: 5.5123\n",
      "Epoch [12/50] Loss D: 0.0277, Loss G: 6.9773\n",
      "Epoch [13/50] Loss D: 0.1368, Loss G: 5.9380\n",
      "Epoch [14/50] Loss D: 0.0093, Loss G: 5.7800\n",
      "Epoch [15/50] Loss D: 0.0108, Loss G: 5.6349\n",
      "Epoch [16/50] Loss D: 0.0158, Loss G: 6.5621\n",
      "Epoch [17/50] Loss D: 0.0188, Loss G: 4.8580\n",
      "Epoch [18/50] Loss D: 0.0120, Loss G: 5.4685\n",
      "Epoch [19/50] Loss D: 0.0217, Loss G: 6.3864\n",
      "Epoch [20/50] Loss D: 0.0027, Loss G: 6.7986\n",
      "Epoch [21/50] Loss D: 0.0052, Loss G: 5.9710\n",
      "Epoch [22/50] Loss D: 0.0083, Loss G: 6.0102\n",
      "Epoch [23/50] Loss D: 0.0049, Loss G: 6.4675\n",
      "Epoch [24/50] Loss D: 0.0076, Loss G: 6.6287\n",
      "Epoch [25/50] Loss D: 0.0033, Loss G: 6.6642\n",
      "Epoch [26/50] Loss D: 0.0717, Loss G: 4.9274\n",
      "Epoch [27/50] Loss D: 0.0010, Loss G: 7.3991\n",
      "Epoch [28/50] Loss D: 0.0010, Loss G: 7.7486\n",
      "Epoch [29/50] Loss D: 0.0050, Loss G: 7.2130\n",
      "Epoch [30/50] Loss D: 0.0200, Loss G: 8.4732\n",
      "Epoch [31/50] Loss D: 0.0012, Loss G: 8.4307\n",
      "Epoch [32/50] Loss D: 0.0020, Loss G: 7.8076\n",
      "Epoch [33/50] Loss D: 0.0282, Loss G: 6.5999\n",
      "Epoch [34/50] Loss D: 0.0026, Loss G: 6.9503\n",
      "Epoch [35/50] Loss D: 0.0104, Loss G: 7.6811\n",
      "Epoch [36/50] Loss D: 0.0042, Loss G: 6.6439\n",
      "Epoch [37/50] Loss D: 0.0056, Loss G: 8.3167\n",
      "Epoch [38/50] Loss D: 0.0037, Loss G: 6.5823\n",
      "Epoch [39/50] Loss D: 0.0041, Loss G: 6.8690\n",
      "Epoch [40/50] Loss D: 0.0008, Loss G: 8.2487\n",
      "Epoch [41/50] Loss D: 0.0040, Loss G: 8.1285\n",
      "Epoch [42/50] Loss D: 0.0011, Loss G: 8.6122\n",
      "Epoch [43/50] Loss D: 0.0118, Loss G: 6.9267\n",
      "Epoch [44/50] Loss D: 0.0002, Loss G: 9.0747\n",
      "Epoch [45/50] Loss D: 0.0024, Loss G: 7.6108\n",
      "Epoch [46/50] Loss D: 0.0026, Loss G: 7.7272\n",
      "Epoch [47/50] Loss D: 0.0009, Loss G: 8.6496\n",
      "Epoch [48/50] Loss D: 0.0032, Loss G: 7.8598\n",
      "Epoch [49/50] Loss D: 0.0002, Loss G: 9.4472\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, 784).to(device)            # - FLATTEN AND MOVE REAL IMAGES TO DEVICE\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        # TRAIN DISCRIMINATOR: MAXIMIZE log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device) # - GENERATE RANDOM NOISE\n",
    "        fake = gen(noise)                               # - GENERATE FAKE IMAGES\n",
    "        disc_real = disc(real).view(-1)                 # - DISCRIMINATOR OUTPUT FOR REAL IMAGES\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))  # - LOSS FOR REAL IMAGES\n",
    "        disc_fake = disc(fake).view(-1)                 # - DISCRIMINATOR OUTPUT FOR FAKE IMAGES\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake)) # - LOSS FOR FAKE IMAGES\n",
    "        lossD = (lossD_real + lossD_fake) / 2           # - TOTAL DISCRIMINATOR LOSS\n",
    "        disc.zero_grad()                                # - RESET DISCRIMINATOR GRADIENTS\n",
    "        lossD.backward(retain_graph=True)               # - BACKPROPAGATE DISCRIMINATOR LOSS\n",
    "        opt_disc.step()                                 # - UPDATE DISCRIMINATOR WEIGHTS\n",
    "\n",
    "        # TRAIN GENERATOR: min log(1 - D(G(z))) <==> MAX log(D(G(z)))\n",
    "        output = disc(fake).view(-1)                    # - DISCRIMINATOR OUTPUT FOR FAKE IMAGES\n",
    "        lossG = criterion(output, torch.ones_like(output)) # - GENERATOR LOSS\n",
    "        gen.zero_grad()                                 # - RESET GENERATOR GRADIENTS\n",
    "        lossG.backward()                                # - BACKPROPAGATE GENERATOR LOSS\n",
    "        opt_gen.step()                                  # - UPDATE GENERATOR WEIGHTS\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "                f\"Loss D: {lossD:.4f}, Loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28) # - GENERATE FAKE IMAGES FROM FIXED NOISE\n",
    "                data = real.reshape(-1, 1, 28, 28)             # - RESHAPE REAL IMAGES\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True) # - CREATE GRID OF FAKE IMAGES\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True) # - CREATE GRID OF REAL IMAGES\n",
    "\n",
    "                writer_fake.add_image(\"Fake Images\", img_grid_fake, global_step=steps) # - LOG FAKE IMAGES\n",
    "                writer_real.add_image(\"Real Images\", img_grid_real, global_step=steps) # - LOG REAL IMAGES\n",
    "\n",
    "                steps += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
